{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PG for Policy Optimization. Using OpenAi Gym and Tensorflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab2 -> Deep Reinforcement Learning - John Schulman MLSS\n",
    "http://rl-gym-doc.s3-website-us-west-2.amazonaws.com/mlss/lab2.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 -> Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym.spaces import Discrete, Box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 -> Choose action accroding to probability distribution (Discrete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_sample(p):\n",
    "    cump = np.cumsum(p)\n",
    "    return (cump > np.random.rand()).argmax()\n",
    "def greedy_sample(p):\n",
    "    return p.argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 -> Do an episode, get observations, actions and rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_episode(agent, env, episode_max_length, render=False):\n",
    "    obss = []\n",
    "    acts = []\n",
    "    rews = []\n",
    "    obs = env.reset()\n",
    "    for i in range(episode_max_length):\n",
    "        obss.append(obs.reshape(-1))\n",
    "        act = agent.act(obs)\n",
    "        acts.append(act)\n",
    "        obs, rew, done, _ = env.step(act)\n",
    "        rews.append(rew)\n",
    "        if render: env.render()\n",
    "        if done: break\n",
    "    return {\n",
    "        \"obs\": np.array(obss),\n",
    "        \"act\": np.array(acts),\n",
    "        \"rew\": np.array(rews)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 -> Compute discounted returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discounted_ret(rew, gamma):\n",
    "    for i in range(len(rew)-1):\n",
    "        rew[-(i+2)] += gamma*rew[-(i+1)]\n",
    "    return rew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 -> Define agent (Discrete & Continuous)\n",
    "- init -> define policy network, linear model\n",
    "    * Discrete: output probability for each action\n",
    "    * Continuous: output action value\n",
    "- act -> compute probability and choose (Discrete) or compute and clip (Continuous)\n",
    "- learn -> main loop, to update parameters from env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class REINFORCEAgentDiscrete(object):\n",
    "    def __init__(self, obs_space, act_space, **usercfg):\n",
    "        obs_dim = obs_space.shape[0]\n",
    "        self.act_dim = act_space.n\n",
    "        self.cfg = dict(episode_max_length=100, timesteps_per_batch=10000,\n",
    "                        n_iter=100, gamma=0.9, lr=0.05, hid_dim=20)\n",
    "        self.cfg.update(usercfg)\n",
    "        self.xs = tf.placeholder(tf.float32, [None, obs_dim])\n",
    "        W1 = weight_variable([obs_dim, self.cfg['hid_dim']])\n",
    "        b1 = bias_variable([self.cfg['hid_dim']])\n",
    "        hs = tf.tanh(tf.matmul(self.xs, W1) + b1)\n",
    "        W2 = weight_variable([self.cfg['hid_dim'], self.act_dim])\n",
    "        b2 = bias_variable([self.act_dim])\n",
    "        self.ps = tf.nn.softmax(tf.matmul(hs, W2) + b2)\n",
    "        self.advs = tf.placeholder(tf.float32, [None])\n",
    "        self.acts_onehot = tf.placeholder(tf.float32, [None, self.act_dim])\n",
    "        loss = tf.reduce_mean(tf.log(tf.reduce_sum(self.ps*self.acts_onehot, 1))*self.advs)\n",
    "        self.optimizer = tf.train.RMSPropOptimizer(learning_rate=self.cfg['lr'], \n",
    "                                              epsilon=1e-9).minimize(loss)\n",
    "        \n",
    "    def act(self, obs):\n",
    "        p = self.sess.run(self.ps, feed_dict={self.xs:obs.reshape(1,-1)})\n",
    "        # act = categorical_sample(p[0])\n",
    "        act = greedy_sample(p[0])\n",
    "        return act\n",
    "        \n",
    "    def learn(self, env):\n",
    "        self.sess = tf.InteractiveSession()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        for iteration in range(self.cfg[\"n_iter\"]):\n",
    "            timestep = 0\n",
    "            episodes = []\n",
    "            while (timestep < self.cfg[\"timesteps_per_batch\"]):\n",
    "                episode = get_episode(self, env, self.cfg[\"episode_max_length\"])\n",
    "                episodes.append(episode)\n",
    "                timestep = timestep + len(episode[\"rew\"])\n",
    "            obss = np.concatenate([episode[\"obs\"] for episode in episodes])\n",
    "            acts = np.concatenate([episode[\"act\"] for episode in episodes])\n",
    "            acts_onehot = np.zeros([len(acts), self.act_dim])\n",
    "            acts_onehot[np.arange(len(acts)), acts] = 1\n",
    "            dis_rets = [discounted_ret(episode[\"rew\"], self.cfg[\"gamma\"]) for episode in episodes]\n",
    "            timesteps_max_length = np.max([len(dis_ret) for dis_ret in dis_rets])\n",
    "            dis_rets_padded = [np.append(dis_ret, np.zeros(timesteps_max_length - len(dis_ret))) for dis_ret in dis_rets]\n",
    "            bs = np.mean(dis_rets_padded, axis=0)\n",
    "            advs = np.concatenate([dis_ret - bs[:len(dis_ret)] for dis_ret in dis_rets])\n",
    "            self.sess.run(self.optimizer, feed_dict={self.xs:obss, self.acts_onehot:acts_onehot, self.advs:advs})\n",
    "            eprews = [np.sum(episode[\"rew\"]) for episode in episodes]\n",
    "            eplens = [len(episode) for episode in episodes]\n",
    "            print(\"Iteration %i. \\n NumEpisodes %i. NumTimeSteps %i. \\n MaxRew %s. MeanRew %s+/-%s. MeanLen %s+/-%s.\" \n",
    "                  % (iteration+1, len(episodes), timestep+1, \n",
    "                     np.max(eprews), np.mean(eprews), np.std(eprews),\n",
    "                     np.mean(eplens), np.std(eplens)))\n",
    "            # get_episode(self, env, self.cfg[\"episode_max_length\"], render=True)\n",
    "        self.sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class REINFORCEAgentContinuous(object):\n",
    "    def __init__(self, obs_space, act_space, **usercfg):\n",
    "        obs_dim = obs_space.shape[0]\n",
    "        act_dim = act_space.shape[0]\n",
    "        self.act_space = act_space\n",
    "        self.cfg = dict(episode_max_length=100, timesteps_per_batch=10000,\n",
    "                        n_iter=100, gamma=0.9, lr=0.05, hid_dim=20)\n",
    "        self.cfg.update(usercfg)\n",
    "        self.xs = tf.placeholder(tf.float32, [None, obs_dim])\n",
    "        self.W1 = weight_variable([obs_dim, self.cfg['hid_dim']])\n",
    "        self.b1 = bias_variable([self.cfg['hid_dim']])\n",
    "        hs = tf.tanh(tf.matmul(self.xs, self.W1) + self.b1)\n",
    "        self.W2 = weight_variable([self.cfg['hid_dim'], act_dim])\n",
    "        self.b2 = bias_variable([act_dim])\n",
    "        self.acts = tf.matmul(hs, self.W2) + self.b2\n",
    "        self.advs = tf.placeholder(tf.float32, [None])\n",
    "        loss = tf.reduce_mean(tf.log(self.acts)*self.advs)\n",
    "        self.optimizer = tf.train.RMSPropOptimizer(learning_rate=self.cfg['lr'], \n",
    "                                              epsilon=1e-9).minimize(loss)\n",
    "        \n",
    "    def act(self, obs):\n",
    "        act = self.sess.run(self.acts, feed_dict={self.xs:obs.reshape(1,-1)})\n",
    "        act = np.clip(act[0], self.act_space.low, self.act_space.high)\n",
    "        return act\n",
    "        \n",
    "    def learn(self, env):\n",
    "        self.sess = tf.InteractiveSession()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        for iteration in range(self.cfg[\"n_iter\"]):\n",
    "            timestep = 0\n",
    "            episodes = []\n",
    "            while (timestep < self.cfg[\"timesteps_per_batch\"]):\n",
    "                episode = get_episode(self, env, self.cfg[\"episode_max_length\"])\n",
    "                episodes.append(episode)\n",
    "                timestep = timestep + len(episode[\"rew\"])\n",
    "            obss = np.concatenate([episode[\"obs\"] for episode in episodes])\n",
    "            acts = np.concatenate([episode[\"act\"] for episode in episodes])\n",
    "            dis_rets = [discounted_ret(episode[\"rew\"], self.cfg[\"gamma\"]) for episode in episodes]\n",
    "            timesteps_max_length = np.max([len(dis_ret) for dis_ret in dis_rets])\n",
    "            dis_rets_padded = [np.append(dis_ret, np.zeros(timesteps_max_length - len(dis_ret))) for dis_ret in dis_rets]\n",
    "            bs = np.mean(dis_rets_padded, axis=0)\n",
    "            advs = np.concatenate([dis_ret - bs[:len(dis_ret)] for dis_ret in dis_rets])\n",
    "            self.sess.run(self.optimizer, feed_dict={self.xs:obss, self.acts:acts, self.advs:advs})\n",
    "            eprews = [np.sum(episode[\"rew\"]) for episode in episodes]\n",
    "            eplens = [len(episode) for episode in episodes]\n",
    "            theta = self.sess.run(self.W1).reshape(-1)\n",
    "            theta = np.append(theta, self.sess.run(self.b1).reshape(-1))\n",
    "            theta = np.append(theta, self.sess.run(self.W2).reshape(-1))\n",
    "            theta = np.append(theta, self.sess.run(self.b2).reshape(-1))\n",
    "            print(\"Iteration %i. \\n NumEpisodes %i. NumTimeSteps %i. \\n MaxRew %s. MeanRew %s+/-%s. MeanLen %s+/-%s.\" \n",
    "                  % (iteration+1, len(episodes), timestep+1, \n",
    "                     np.max(eprews), np.mean(eprews), np.std(eprews),\n",
    "                     np.mean(eplens), np.std(eplens)))\n",
    "            print(\" ThetaMean %s. ThetaStd %s\" % (np.mean(theta), np.std(theta)))\n",
    "            # get_episode(self, env, self.cfg[\"episode_max_length\"], render=True)\n",
    "        self.sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 -> Main run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-04-17 10:15:26,276] Making new env: Pendulum-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7515.51499279. MeanRew -12389.8192059+/-2014.81305478. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195458. ThetaStd 0.0789361\n",
      "Iteration 2. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7614.51113772. MeanRew -13282.3333011+/-2823.73948515. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195458. ThetaStd 0.0789361\n",
      "Iteration 3. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7531.97731184. MeanRew -12043.4531024+/-2498.28530066. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195459. ThetaStd 0.0789361\n",
      "Iteration 4. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7628.78817855. MeanRew -12448.9913581+/-2778.90335197. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195458. ThetaStd 0.0789361\n",
      "Iteration 5. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7470.60254188. MeanRew -12711.9485615+/-3015.09361482. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195458. ThetaStd 0.0789361\n",
      "Iteration 6. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7492.35605448. MeanRew -12785.7719894+/-3130.12856909. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195458. ThetaStd 0.0789361\n",
      "Iteration 7. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7608.68118444. MeanRew -12704.1117938+/-2786.17501075. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195458. ThetaStd 0.0789361\n",
      "Iteration 8. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -6220.44773689. MeanRew -12333.6375472+/-2458.65383464. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195459. ThetaStd 0.0789361\n",
      "Iteration 9. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -6654.5016116. MeanRew -12156.1140107+/-3065.21804229. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195459. ThetaStd 0.0789361\n",
      "Iteration 10. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7554.77913795. MeanRew -12228.9401051+/-2853.33642153. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195458. ThetaStd 0.0789361\n",
      "Iteration 11. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7246.28736307. MeanRew -12359.1273911+/-2852.57186723. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195458. ThetaStd 0.0789361\n",
      "Iteration 12. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7538.32782028. MeanRew -12431.929331+/-2323.51637186. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195458. ThetaStd 0.0789361\n",
      "Iteration 13. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7565.79741436. MeanRew -12279.809413+/-2645.50527837. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195458. ThetaStd 0.0789361\n",
      "Iteration 14. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7343.70688264. MeanRew -12483.7745525+/-2585.3245457. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195458. ThetaStd 0.0789361\n",
      "Iteration 15. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7466.39295958. MeanRew -12366.2797274+/-3264.13257522. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195458. ThetaStd 0.0789361\n",
      "Iteration 16. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7596.760907. MeanRew -12100.8988112+/-2691.54644123. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195458. ThetaStd 0.0789361\n",
      "Iteration 17. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7587.52948862. MeanRew -12969.0232787+/-2935.8158732. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195458. ThetaStd 0.0789361\n",
      "Iteration 18. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7573.65575309. MeanRew -13071.6620245+/-2866.96330674. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195458. ThetaStd 0.0789361\n",
      "Iteration 19. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7680.78362321. MeanRew -12725.1648941+/-2690.2836821. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195458. ThetaStd 0.0789361\n",
      "Iteration 20. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7454.38200754. MeanRew -11597.7721998+/-2210.88522452. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195458. ThetaStd 0.0789362\n",
      "Iteration 21. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7336.15445817. MeanRew -12804.949255+/-2675.45584946. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195457. ThetaStd 0.0789362\n",
      "Iteration 22. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -9437.47819609. MeanRew -12712.8878137+/-2366.31038733. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195457. ThetaStd 0.0789362\n",
      "Iteration 23. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -8488.74997949. MeanRew -12523.305168+/-2195.93448187. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195457. ThetaStd 0.0789362\n",
      "Iteration 24. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7674.5152803. MeanRew -12827.3929348+/-2484.29236617. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195457. ThetaStd 0.0789362\n",
      "Iteration 25. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7401.2502384. MeanRew -13190.9642194+/-2831.37644262. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195457. ThetaStd 0.0789362\n",
      "Iteration 26. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7351.78197208. MeanRew -11995.3495491+/-2610.66472332. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195457. ThetaStd 0.0789362\n",
      "Iteration 27. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7476.68793503. MeanRew -12969.1859649+/-2528.12590113. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195457. ThetaStd 0.0789362\n",
      "Iteration 28. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7199.45505852. MeanRew -12312.803381+/-2776.01300568. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195457. ThetaStd 0.0789362\n",
      "Iteration 29. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7421.99181207. MeanRew -12869.7200972+/-3077.24286902. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195456. ThetaStd 0.0789362\n",
      "Iteration 30. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7523.06920514. MeanRew -11839.7695584+/-2562.08542036. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195455. ThetaStd 0.0789362\n",
      "Iteration 31. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7517.71266917. MeanRew -12871.2565812+/-2321.62810585. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195455. ThetaStd 0.0789362\n",
      "Iteration 32. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7377.44044717. MeanRew -12119.8479445+/-2688.91040175. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195455. ThetaStd 0.0789362\n",
      "Iteration 33. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7428.90894726. MeanRew -12108.4042612+/-2611.82407165. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195455. ThetaStd 0.0789362\n",
      "Iteration 34. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7576.82111625. MeanRew -12503.4125499+/-2538.08061037. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195455. ThetaStd 0.0789362\n",
      "Iteration 35. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7530.2807103. MeanRew -12528.0130029+/-2720.37087498. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195455. ThetaStd 0.0789362\n",
      "Iteration 36. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -6316.41058039. MeanRew -13407.0428328+/-3050.40521942. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195455. ThetaStd 0.0789362\n",
      "Iteration 37. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7584.0484467. MeanRew -12524.0571958+/-2913.1008017. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195455. ThetaStd 0.0789362\n",
      "Iteration 38. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -8224.40914963. MeanRew -12934.5106939+/-2522.21193856. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195454. ThetaStd 0.0789362\n",
      "Iteration 39. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7535.37607304. MeanRew -13001.8134657+/-2906.38722313. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195453. ThetaStd 0.0789363\n",
      "Iteration 40. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7577.14448022. MeanRew -12133.3440282+/-2520.05120409. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195453. ThetaStd 0.0789363\n",
      "Iteration 41. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7367.09195721. MeanRew -13116.2477642+/-2894.77776587. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.019545. ThetaStd 0.0789365\n",
      "Iteration 42. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7310.19776695. MeanRew -13308.3620974+/-3566.40701952. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195451. ThetaStd 0.0789365\n",
      "Iteration 43. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7578.98512712. MeanRew -12531.8888351+/-2628.84200874. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195451. ThetaStd 0.0789365\n",
      "Iteration 44. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7591.06487711. MeanRew -12328.0458787+/-2563.94256044. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.019545. ThetaStd 0.0789366\n",
      "Iteration 45. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -8043.75545236. MeanRew -12208.3911459+/-2537.01553596. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.019545. ThetaStd 0.0789366\n",
      "Iteration 46. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -8765.08348206. MeanRew -13544.4123678+/-3084.62101619. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.019545. ThetaStd 0.0789365\n",
      "Iteration 47. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7537.43735048. MeanRew -12681.2372355+/-2786.46438629. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195451. ThetaStd 0.0789365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 48. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7358.74763456. MeanRew -12438.0803054+/-2728.65886544. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195453. ThetaStd 0.0789365\n",
      "Iteration 49. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7585.33391206. MeanRew -12781.0288429+/-2490.58298229. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195453. ThetaStd 0.0789365\n",
      "Iteration 50. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7540.44044986. MeanRew -13043.6316356+/-2676.51875894. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195453. ThetaStd 0.0789365\n",
      "Iteration 51. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7429.98645111. MeanRew -11739.144507+/-2735.2317265. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195452. ThetaStd 0.0789365\n",
      "Iteration 52. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7524.66079614. MeanRew -13048.47924+/-2659.36685862. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195468. ThetaStd 0.0789353\n",
      "Iteration 53. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7753.24042689. MeanRew -12770.2507449+/-2676.55193009. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195468. ThetaStd 0.0789352\n",
      "Iteration 54. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7677.20183372. MeanRew -12916.228653+/-3055.74332563. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195466. ThetaStd 0.0789351\n",
      "Iteration 55. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7186.92860229. MeanRew -13014.6786452+/-2849.22677708. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195466. ThetaStd 0.0789351\n",
      "Iteration 56. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -9308.79582043. MeanRew -12716.0428378+/-2272.11872602. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195465. ThetaStd 0.0789351\n",
      "Iteration 57. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -8527.24759036. MeanRew -13227.5421424+/-2448.69268086. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195465. ThetaStd 0.0789351\n",
      "Iteration 58. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7611.13635674. MeanRew -12651.6310248+/-2679.82305652. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195465. ThetaStd 0.0789351\n",
      "Iteration 59. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -9342.71544967. MeanRew -13418.7450749+/-2553.49038348. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195473. ThetaStd 0.0789343\n",
      "Iteration 60. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7508.74700555. MeanRew -13230.9346614+/-2650.50461179. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195472. ThetaStd 0.0789343\n",
      "Iteration 61. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7404.11653938. MeanRew -12408.5254281+/-2999.73655153. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195472. ThetaStd 0.0789343\n",
      "Iteration 62. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7343.80938622. MeanRew -12198.231861+/-2249.26890756. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195462. ThetaStd 0.0789348\n",
      "Iteration 63. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7582.56149479. MeanRew -12832.5300787+/-2673.65741043. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195441. ThetaStd 0.0789362\n",
      "Iteration 64. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7513.99630782. MeanRew -12776.6762679+/-2553.15986174. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195441. ThetaStd 0.0789361\n",
      "Iteration 65. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7330.97150458. MeanRew -13015.1636577+/-2908.51628137. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195439. ThetaStd 0.0789361\n",
      "Iteration 66. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7548.88591998. MeanRew -12927.6252353+/-2691.1793653. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195443. ThetaStd 0.0789362\n",
      "Iteration 67. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -8609.45580781. MeanRew -12415.6731689+/-2938.13168963. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195443. ThetaStd 0.0789362\n",
      "Iteration 68. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -6995.0300956. MeanRew -12691.7866451+/-2657.564703. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195438. ThetaStd 0.0789372\n",
      "Iteration 69. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7319.30092498. MeanRew -12553.3118143+/-2978.19656043. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195438. ThetaStd 0.0789371\n",
      "Iteration 70. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7560.83534225. MeanRew -13048.5174269+/-2744.18210292. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195437. ThetaStd 0.0789375\n",
      "Iteration 71. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7601.26674708. MeanRew -12883.0979258+/-2627.13211428. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195437. ThetaStd 0.0789374\n",
      "Iteration 72. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7045.82562134. MeanRew -12433.6186943+/-2433.79708256. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195434. ThetaStd 0.0789376\n",
      "Iteration 73. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7605.93926827. MeanRew -12951.0705388+/-2515.13304389. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195424. ThetaStd 0.0789384\n",
      "Iteration 74. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7549.85629809. MeanRew -12397.1347078+/-2533.62399641. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.01955. ThetaStd 0.0789319\n",
      "Iteration 75. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7419.7791439. MeanRew -12740.4553537+/-2812.58025923. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195507. ThetaStd 0.0789318\n",
      "Iteration 76. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7479.82215013. MeanRew -12908.4867916+/-2333.02388532. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195525. ThetaStd 0.078931\n",
      "Iteration 77. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -8399.76060154. MeanRew -12637.4881901+/-2753.80096786. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195527. ThetaStd 0.078931\n",
      "Iteration 78. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7388.95557308. MeanRew -13129.3389665+/-2843.00494475. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195521. ThetaStd 0.0789306\n",
      "Iteration 79. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7422.93464846. MeanRew -12028.3336423+/-2724.70232701. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195517. ThetaStd 0.0789306\n",
      "Iteration 80. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7459.84072841. MeanRew -12830.7628686+/-2854.51377352. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195513. ThetaStd 0.0789301\n",
      "Iteration 81. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7363.48355357. MeanRew -12482.6878135+/-3037.51393631. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195517. ThetaStd 0.0789301\n",
      "Iteration 82. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7973.19430161. MeanRew -12483.2319386+/-2374.90146587. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195517. ThetaStd 0.0789301\n",
      "Iteration 83. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7811.1041964. MeanRew -13048.5092924+/-2581.65760941. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195528. ThetaStd 0.0789297\n",
      "Iteration 84. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -8753.75129346. MeanRew -12995.3794136+/-2688.58027232. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195528. ThetaStd 0.0789297\n",
      "Iteration 85. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7616.36218305. MeanRew -12912.4196369+/-2542.65184392. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195539. ThetaStd 0.0789296\n",
      "Iteration 86. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7588.56201033. MeanRew -12740.7062386+/-2607.63082427. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195544. ThetaStd 0.0789296\n",
      "Iteration 87. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -6486.77095978. MeanRew -12860.2701579+/-2712.49968097. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195534. ThetaStd 0.0789295\n",
      "Iteration 88. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7602.65304632. MeanRew -12346.5586986+/-2820.38400525. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195515. ThetaStd 0.0789303\n",
      "Iteration 89. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7445.12560206. MeanRew -12204.6744175+/-2681.46947414. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195516. ThetaStd 0.0789303\n",
      "Iteration 90. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7617.66281976. MeanRew -12894.811299+/-2727.46333954. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195509. ThetaStd 0.0789305\n",
      "Iteration 91. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7558.0038708. MeanRew -13343.8093992+/-3124.56394375. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195506. ThetaStd 0.0789303\n",
      "Iteration 92. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7527.80588952. MeanRew -12546.1121462+/-2505.49593493. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195505. ThetaStd 0.078931\n",
      "Iteration 93. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7762.59320296. MeanRew -12464.419605+/-2646.28584437. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195508. ThetaStd 0.0789304\n",
      "Iteration 94. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -6836.96230863. MeanRew -12889.4571848+/-2956.16647765. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.019551. ThetaStd 0.0789305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 95. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -6445.15187868. MeanRew -12482.4543457+/-2585.97346251. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195502. ThetaStd 0.0789303\n",
      "Iteration 96. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7713.69727801. MeanRew -12545.9142682+/-2462.81875944. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195508. ThetaStd 0.0789303\n",
      "Iteration 97. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -9366.84729579. MeanRew -13439.0412477+/-2736.17905238. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195513. ThetaStd 0.0789307\n",
      "Iteration 98. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7604.14719249. MeanRew -12810.555562+/-3169.02946115. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195514. ThetaStd 0.0789307\n",
      "Iteration 99. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7587.10365705. MeanRew -12378.5853103+/-2270.21489578. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195483. ThetaStd 0.0789332\n",
      "Iteration 100. \n",
      " NumEpisodes 50. NumTimeSteps 10001. \n",
      " MaxRew -7588.50901464. MeanRew -12956.2984041+/-2543.60910491. MeanLen 3.0+/-0.0.\n",
      " ThetaMean 0.0195503. ThetaStd 0.0789334\n"
     ]
    }
   ],
   "source": [
    "# env = gym.make(\"Acrobot-v1\") # Discrete\n",
    "env = gym.make(\"Pendulum-v0\") # Continuous\n",
    "if isinstance(env.action_space, Discrete):\n",
    "    agent = REINFORCEAgentDiscrete(env.observation_space, env.action_space, \n",
    "                                   episode_max_length=env.spec.timestep_limit)\n",
    "elif isinstance(env.action_space, Box):\n",
    "    agent = REINFORCEAgentContinuous(env.observation_space, env.action_space, \n",
    "                                     episode_max_length=env.spec.timestep_limit)\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "agent.learn(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
