{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trains an agent with (stochastic) Policy Gradients on Pong. Uses OpenAI Gym."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 -> Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "2 -> Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_dim = 80*80\n",
    "hidden_dim = 200\n",
    "output_dim = 1\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 0.99\n",
    "gamma = 0.99\n",
    "batch_size = 5 # update weights every %batch_size% episodes\n",
    "test_interval = 10 # test every %test_interval% episodes\n",
    "test_episode = 10 # test %test_episodes% episodes\n",
    "snapshot = 20 # save model every %snapshot% episodes\n",
    "snapshot_path = \"./model/\"\n",
    "log_path = \"./log/\" + str(time.time()) + \".log\"\n",
    "logfile = open(log_path, \"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 -> Initialize policy parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = {}\n",
    "model[\"W1\"] = np.random.rand(hidden_dim, input_dim)\n",
    "model[\"W2\"] = np.random.rand(output_dim, hidden_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 -> Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    image = image[35:195] # crop to 160*160*3\n",
    "    image = image[::2,::2,0] # downsample by factor of 2 80*80\n",
    "    image[image==109] = 0 # erase background\n",
    "    image[image!=0] = 1 # paddles,ball set to 1\n",
    "    return image.astype(np.float).ravel() # uint8 to float and 80*80 to 6400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 -> Policy forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "def forward(x):\n",
    "    h = np.dot(model[\"W1\"], x.reshape(input_dim,1))\n",
    "    h[h<0] = 0\n",
    "    y = np.dot(model[\"W2\"], h)\n",
    "    p = softmax(y)\n",
    "    return h, p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 -> Policy backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backward(experience):\n",
    "    grad = {}\n",
    "    advantages = discounted_rewards(experience[\"rewards\"]).reshape(1, -1)\n",
    "    gradlogp2 = (1 - experience[\"actions\"] - experience[\"aprobs\"]) * experience[\"hiddens\"]\n",
    "    grad[\"W2\"] = np.dot(advantages, gradlogp2)\n",
    "    experience[\"hiddens\"][experience[\"hiddens\"]>0] = 1\n",
    "    gradlogp1 = experience[\"hiddens\"].reshape(-1, hidden_dim, 1) * experience[\"states\"].reshape(-1, 1, input_dim)\n",
    "    gradlogp1 = np.array(model[\"W2\"]).reshape(1, hidden_dim, 1) * gradlogp1\n",
    "    gradlogp1 = (1 - experience[\"actions\"] - experience[\"aprobs\"]).reshape(-1,1,1) * gradlogp1\n",
    "    grad[\"W1\"] = np.sum(advantages.reshape(-1, 1, 1) * gradlogp1, axis=0)\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def zero_grad():\n",
    "    grad = {}\n",
    "    for name, weight in model.items():\n",
    "        grad[name] = np.zeros(weight.shape)\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discounted_rewards(rewards):\n",
    "    for i in range(len(rewards)-1):\n",
    "        rewards[-(i+2)] = rewards[-(i+2)] + gamma*rewards[-(i+1)]\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_weights(grad):\n",
    "    for name in model:\n",
    "        model[name] = model[name] + learning_rate * grad[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clear_experience():\n",
    "    experience = {}\n",
    "    experience[\"states\"] = np.array([])\n",
    "    experience[\"hiddens\"] = np.array([])\n",
    "    experience[\"aprobs\"] = np.array([])\n",
    "    experience[\"actions\"] = np.array([])\n",
    "    experience[\"rewards\"] = np.array([])\n",
    "    return experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def insert_experience(experience, state, hidden, aprob, action, reward):\n",
    "    if (experience[\"states\"].shape[0] != 0):\n",
    "        experience[\"states\"] = np.vstack((experience[\"states\"], state.reshape(1, input_dim)))\n",
    "        experience[\"hiddens\"] = np.vstack((experience[\"hiddens\"], hidden.reshape(1, hidden_dim)))\n",
    "        experience[\"aprobs\"] = np.vstack((experience[\"aprobs\"], np.array(aprob).reshape(1, 1)))\n",
    "        experience[\"actions\"] = np.vstack((experience[\"actions\"], np.array(action).reshape(1, 1)))\n",
    "        experience[\"rewards\"] = np.vstack((experience[\"rewards\"], np.array(reward).reshape(1, 1)))\n",
    "    else:\n",
    "        experience[\"states\"] = state.reshape(1, input_dim)\n",
    "        experience[\"hiddens\"] = hidden.reshape(1, hidden_dim)\n",
    "        experience[\"aprobs\"] = np.array(aprob).reshape(1, 1)\n",
    "        experience[\"actions\"] = np.array(action).reshape(1, 1)\n",
    "        experience[\"rewards\"] = np.array(reward).reshape(1, 1)\n",
    "    return experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_model(episode_num):\n",
    "    prefix = \"Pongv0-PG-episode-\"\n",
    "    surfix = \".npy\"\n",
    "    path = snapshot_path + prefix + str(episode_num) + surfix\n",
    "    np.save(path, model)\n",
    "    print(\"Save model \" + path)\n",
    "    logfile.write(\"Save model \" + path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    test_num = 0\n",
    "    total_reward = 0\n",
    "    while test_num < test_episode:\n",
    "        observation = env.reset()\n",
    "        prev_obs = None\n",
    "        cur_obs = preprocess(observation)\n",
    "        while True:\n",
    "            state = cur_obs - (prev_obs if prev_obs is not None else 0)\n",
    "            hidden, aprob = forward(state)\n",
    "            action = 2 if random.random() <= aprob else 3\n",
    "            observation, reward, done, info = env.step(action)\n",
    "            total_reward += reward\n",
    "            prev_obs = cur_obs\n",
    "            cur_obs = preprocess(observation)\n",
    "            if done:\n",
    "                print(\"Test episode \" + str(test_num+1) + \" terminated!\")\n",
    "                logfile.write(\"Test episode \" + str(test_num+1) + \" terminated!\")\n",
    "                break\n",
    "        test_num = test_num + 1\n",
    "    avg_reward = float(total_reward) / float(test_episode)\n",
    "    print(\"Average rewards: \" + str(avg_reward))\n",
    "    logfile.write(\"Average rewards: \" + str(avg_reward))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-04-13 21:19:05,409] Making new env: Pong-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train episode 1 terminated!\n",
      "Train episode 2 terminated!\n",
      "Train episode 3 terminated!\n",
      "Train episode 4 terminated!\n",
      "Train episode 5 terminated!\n",
      "Train episode 6 terminated!\n",
      "Train episode 7 terminated!\n",
      "Train episode 8 terminated!\n",
      "Train episode 9 terminated!\n",
      "Train episode 10 terminated!\n",
      "Test episode 1 terminated!\n",
      "Test episode 2 terminated!\n",
      "Test episode 3 terminated!\n",
      "Test episode 4 terminated!\n",
      "Test episode 5 terminated!\n",
      "Test episode 6 terminated!\n",
      "Test episode 7 terminated!\n",
      "Test episode 8 terminated!\n",
      "Test episode 9 terminated!\n",
      "Test episode 10 terminated!\n",
      "Average rewards: -20.3\n",
      "Train episode 11 terminated!\n",
      "Train episode 12 terminated!\n",
      "Train episode 13 terminated!\n",
      "Train episode 14 terminated!\n",
      "Train episode 15 terminated!\n",
      "Train episode 16 terminated!\n",
      "Train episode 17 terminated!\n",
      "Train episode 18 terminated!\n",
      "Train episode 19 terminated!\n",
      "Train episode 20 terminated!\n",
      "Test episode 1 terminated!\n",
      "Test episode 2 terminated!\n",
      "Test episode 3 terminated!\n",
      "Test episode 4 terminated!\n",
      "Test episode 5 terminated!\n",
      "Test episode 6 terminated!\n",
      "Test episode 7 terminated!\n",
      "Test episode 8 terminated!\n",
      "Test episode 9 terminated!\n",
      "Test episode 10 terminated!\n",
      "Average rewards: -20.5\n",
      "Save model ./model/Pongv0-PG-episode-20.npy\n",
      "Train episode 21 terminated!\n",
      "Train episode 22 terminated!\n",
      "Train episode 23 terminated!\n",
      "Train episode 24 terminated!\n",
      "Train episode 25 terminated!\n",
      "Train episode 26 terminated!\n",
      "Train episode 27 terminated!\n",
      "Train episode 28 terminated!\n",
      "Train episode 29 terminated!\n",
      "Train episode 30 terminated!\n",
      "Test episode 1 terminated!\n",
      "Test episode 2 terminated!\n",
      "Test episode 3 terminated!\n",
      "Test episode 4 terminated!\n",
      "Test episode 5 terminated!\n",
      "Test episode 6 terminated!\n",
      "Test episode 7 terminated!\n",
      "Test episode 8 terminated!\n",
      "Test episode 9 terminated!\n",
      "Test episode 10 terminated!\n",
      "Average rewards: -20.8\n",
      "Train episode 31 terminated!\n",
      "Train episode 32 terminated!\n",
      "Train episode 33 terminated!\n",
      "Train episode 34 terminated!\n",
      "Train episode 35 terminated!\n",
      "Train episode 36 terminated!\n",
      "Train episode 37 terminated!\n",
      "Train episode 38 terminated!\n",
      "Train episode 39 terminated!\n",
      "Train episode 40 terminated!\n",
      "Test episode 1 terminated!\n",
      "Test episode 2 terminated!\n",
      "Test episode 3 terminated!\n",
      "Test episode 4 terminated!\n",
      "Test episode 5 terminated!\n",
      "Test episode 6 terminated!\n",
      "Test episode 7 terminated!\n",
      "Test episode 8 terminated!\n",
      "Test episode 9 terminated!\n",
      "Test episode 10 terminated!\n",
      "Average rewards: -20.4\n",
      "Save model ./model/Pongv0-PG-episode-40.npy\n",
      "Train episode 41 terminated!\n",
      "Train episode 42 terminated!\n",
      "Train episode 43 terminated!\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"Pong-v0\")\n",
    "episode_num = 1\n",
    "grads = zero_grad()\n",
    "while True:\n",
    "    observation = env.reset()\n",
    "    experience = clear_experience()\n",
    "    prev_obs = None\n",
    "    cur_obs = preprocess(observation)\n",
    "    while True:\n",
    "        state = cur_obs - (prev_obs if prev_obs is not None else 0)\n",
    "        hidden, aprob = forward(state)\n",
    "        action = 2 if random.random() <= aprob else 3\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        action = 0 if action == 2 else 1\n",
    "        experience = insert_experience(experience, state, hidden, aprob, action, reward)\n",
    "        prev_obs = cur_obs\n",
    "        cur_obs = preprocess(observation)\n",
    "        if done:\n",
    "            print(\"Train episode \" + str(episode_num) + \" terminated!\")\n",
    "            logfile.write(\"Train episode \" + str(episode_num) + \" terminated!\")\n",
    "            grad = backward(experience)\n",
    "            for name in grad:\n",
    "                grads[name] = grads[name] + grad[name]\n",
    "            break\n",
    "    if episode_num % batch_size == 0:\n",
    "        update_weights(grads)\n",
    "        grads = zero_grad()\n",
    "    if episode_num % test_interval == 0:\n",
    "        test()\n",
    "    if episode_num % snapshot == 0:\n",
    "        save_model(episode_num)\n",
    "    episode_num = episode_num + 1\n",
    "logfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
